<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Basic Meta Tags -->
  <meta name="title" content="Arch Inductive Bias">
  <meta name="description" content="Horses for Courses: Classical Ciphers as a Testbed for Architectural Inductive Bias Evaluation">
  <meta name="author" content="Durga Sharma">
  
  <title>Arch Inductive Bias</title>

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="./favicon.png"
  
  <!-- CSS -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>

  <style>
  /* Clean Table Style */
  .custom-table-container {
    padding: 20px 0;
    display: flex;
    justify-content: center;
  }

  .pretty-table {
    border-collapse: collapse;
    width: 100%;
    max-width: 700px;
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    overflow: hidden;
    background-color: #ffffff;
    font-family: 'Inter', sans-serif;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
  }

  .pretty-table th {
    background-color: #f8f9fa;
    padding: 14px 16px;
    text-align: left;
    border-bottom: 2px solid #dee2e6;
    font-weight: 600;
    font-size: 0.9rem;
    color: #495057;
    text-transform: uppercase;
    letter-spacing: 0.5px;
  }

  .pretty-table td {
    padding: 12px 16px;
    border-bottom: 1px solid #f0f0f0;
    color: #212529;
    font-size: 0.95rem;
  }

  .pretty-table tbody tr:hover {
    background-color: #f8f9fa;
  }

  .pretty-table tbody tr:last-child td {
    border-bottom: none;
  }

  .pretty-table td:first-child {
    font-weight: 500;
    color: #2c3e50;
  }

  .col-tweets {
    font-weight: 500;
    color: #495057;
  }

  /* Results Section Styling */
  .result-item {
    margin-bottom: 60px;
  }

  .result-item img {
    width: 100%;
    max-width: 900px;
    margin: 0 auto;
    display: block;
    border-radius: 8px;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
  }

  .result-item .subtitle {
    margin-top: 20px;
    font-size: 1rem;
    line-height: 1.6;
    color: #4a5568;
  }
  </style>
</head>
<body>

  <main id="main-content">
  
  <!-- Hero Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Horses for Courses: Classical Ciphers as a Testbed for Architectural Inductive Bias Evaluation</h1>
            
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://durgarsharma.github.io/" target="_blank">Durga Sharma</a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=A4eUrCUAAAAJ&hl=en" target="_blank">Rahul Johari</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">University School of Automation and Robotics, GGSIPU, New Delhi</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
              

                <!-- GitHub -->
                <span class="link-block">
                  <a href="https://github.com/durgarsharma/architectural-inductive-bias" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
                </span>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              This study systematically explores the potential of machine learning models to decrypt text without prior knowledge of the cipher key or explicit rules. Focusing on the feasibility of Zero-Shot generalization, the research compares four dominant neural network architectures: MLP, Character CNN, LSTM, and Transformer. The project is executed across four phases, commencing with a 1,000 article English corpus and extending to Hindi, Greek, and constructed languages (testing systematic variations in morphology, syntax, and phonology). The MLP was trained on five ciphers and evaluated on a held-out sixth cipher in Phase 1, establishing the architectural baseline. Experimental results from the MLP show low to moderate accuracy (50%–65%) with negative generalization gaps, conclusively proving that position independent networks lack the representational capacity for robust decryption. In contrast, the subsequent phases demonstrate that LSTMs, with their explicit sequential memory, achieve near-perfect decryption on position-dependent ciphers like Vigenère, while the Transformer surprisingly fails due to over generalization. The research culminates by challenging the best-performing models with modern block ciphers (AES/DES), serving as a negative control. The expected universal failure validates that neural network success on classical ciphers relies solely on exploitable statistical patternsnot true cryptographic deduction. These findings provide a definitive architectural hierarchy and establish the fundamental boundaries of pattern-based learning across diverse linguistic structures.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Key Results - Vertical Layout -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Key Results</h2>
        
        <!-- Result 1 -->
        <h3 class="title is-4 has-text-centered">Result 1: Recurrent Memory Solves Sequential Ciphers Universally</h3>
        <div class="result-item">
          <img src="static/images/fig_lstm_script_invariant" alt="Result 2"/>
          <h2 class="subtitle has-text-centered">
            LSTM achieves 99%+ word accuracy on Vigenère across English, Hindi, and Greek with standard deviation ≤0.13%
          </h2>
        </div>
        
        <!-- Result 2 -->
        <h3 class="title is-4 has-text-centered">Result 2: Transformers Catastrophically Fail on Simple Sequences</h3>
        <div class="result-item">
          <img src="static/images/fig_vigenere_architecture_comparison.png" alt="Result 2"/>
          <h2 class="subtitle has-text-centered">
            Vigenère performance comparison: LSTM 99.91%, CNN 93.06%, Transformer 9.88%, showing catastrophic attention failure
          </h2>
        </div>
        
        <!-- Result 3 -->
        <h3 class="title is-4 has-text-centered">Result 3: Linguistic Complexity Exposes Fundamental Limits</h3>
        <div class="result-item">
          <div class="columns is-centered">
            <div class="column is-3">
              <img src="static/images/fig_morphology_collapse.png" alt="Morphology"/>
            </div>
            <div class="column is-3">
              <img src="static/images/fig_phonology_inversion.png" alt="Phonology"/>
            </div>
          <h2 class="subtitle has-text-centered">
            Universal architectural collapse: all models achieve 0-5% word accuracy on morphologically complex Vigenère despite 91% character accuracy, showing long words (10-20 chars) exponentially amplify errors.
          </h2>
        </div>
        
        <!-- Result 4 -->
        <h3 class="title is-4 has-text-centered">Result 4: Negative Controls Prove Pattern Dependency</h3>
        <div class="result-item">
          <div class="columns is-centered">
            <div class="column is-6">
              <img src="static/images/AES_all_models.png" alt="AES Negative Control"/>
            </div>
            <div class="column is-6">
              <img src="static/images/DES_all_models.png" alt="DES Negative Control"/>
            </div>
          </div>
          <h2 class="subtitle has-text-centered">
            All architectures achieve 0.00% word accuracy on AES and DES encryption, confirming neural cryptanalysis depends entirely on exploitable statistical patterns absent in modern secure ciphers.
          </h2>
        </div>
                
              </div>
            </div>
          </section>

  <!-- Dataset Section -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Dataset</h2>
          <div class="content has-text-justified">
            <p>
              We collected 27,314 tweets directed at six Indian athletes (2013-2023), with 12.01% exhibiting Hindi-English code-mixing. Code-mixing intensity varied from 0.5% to 48.1% across athletes, with balanced language integration (mean Hindi ratio = 0.58) indicating genuine bilingual expression rather than superficial switching.
            </p>
            <p>
              Three independent annotators labeled 498 stratified-sampled tweets (83 per athlete), achieving moderate agreement (Cohen's κ = 0.586). Gold-standard labels derived via majority voting reveal 48.4% negative sentiment, establishing reliable benchmarks for evaluating automated systems on code-mixed content.
            </p>
            
            <div class="custom-table-container">
              <table class="pretty-table">
                <thead>
                  <tr>
                    <th>Athlete</th>
                    <th>Sport</th>
                    <th>Period</th>
                    <th>Tweets</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Virat Kohli</td>
                    <td>Cricket</td>
                    <td>May-Oct 2017</td>
                    <td class="col-tweets">4,892</td>
                  </tr>
                  <tr>
                    <td>Harmanpreet Kaur</td>
                    <td>Cricket</td>
                    <td>May-Oct 2017</td>
                    <td class="col-tweets">4,156</td>
                  </tr>
                  <tr>
                    <td>Vijender Singh</td>
                    <td>Boxing</td>
                    <td>Feb-Jul 2013</td>
                    <td class="col-tweets">4,234</td>
                  </tr>
                  <tr>
                    <td>Sarita Devi</td>
                    <td>Boxing</td>
                    <td>Sep 2014-Feb 2015</td>
                    <td class="col-tweets">4,421</td>
                  </tr>
                  <tr>
                    <td>Sushil Kumar</td>
                    <td>Wrestling</td>
                    <td>May-Oct 2021</td>
                    <td class="col-tweets">4,567</td>
                  </tr>
                  <tr>
                    <td>Sakshi Malik</td>
                    <td>Wrestling</td>
                    <td>Jan-Jun 2023</td>
                    <td class="col-tweets">5,044</td>
                  </tr>
                </tbody>
              </table>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>

  
  <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Examples</h2>
        <div class="content has-text-justified">
          
          <p>
            <strong>Code-Mixed Hi-En:</strong><br>
            <em>"Yaar, kal ka match bohot intense tha, but Virat ne amazing performance di!"</em>
          </p>
          <p>
            <strong>Translated Tweet:</strong><br>
            <em>"Man, yesterday's match was very intense, but Virat gave an amazing performance!"</em>
          </p>

          <br>

          <p>
            <strong>Code-Switched Hi-En:</strong><br>
            <em>"I can't believe we lost the game, lekin Virat ne bohot achha khela."</em>
          </p>
          <p>
            <strong>Translated Tweet:</strong><br>
            <em>"I can't believe we lost the game, but Virat played really well."</em>
          </p>

        </div>
      </div>
    </div>
  </div>
</section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  </main>

</body>
</html>
